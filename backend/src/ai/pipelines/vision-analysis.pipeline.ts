// backend/src/ai/pipelines/vision-analysis.pipeline.ts

import { Injectable, Logger } from '@nestjs/common';
import { ChatOpenAI } from '@langchain/openai';
import { AIMessage } from '@langchain/core/messages';
import * as fs from 'fs';
import * as path from 'path';

/**
 * Interface para resultado da an√°lise visual
 */
export interface VisionAnalysisResult {
  category: string;
  colors: string[];
  style: string;
  materials: string[];
  features: string[];
  detailedDescription: string;
}

/**
 * Interface para conte√∫do da mensagem (pode ser string ou objeto complexo)
 */
interface MessageContent {
  text?: string;
  type?: string;
  [key: string]: unknown;
}

/**
 * VisionAnalysisPipeline
 *
 * Pipeline especializada para an√°lise de imagens de produtos
 * usando GPT-4o-mini com capacidade de vis√£o.
 *
 * Extrai: categoria, cores, materiais, estilo, caracter√≠sticas visuais
 */
@Injectable()
export class VisionAnalysisPipeline {
  private readonly logger = new Logger(VisionAnalysisPipeline.name);

  /**
   * Modelo com suporte a vis√£o.
   * GPT-4o-mini suporta imagens!
   */
  private readonly visionModel = new ChatOpenAI({
    modelName: 'gpt-4o-mini',
    temperature: 0.3, // Baixa temperatura para an√°lise objetiva
    apiKey: process.env.OPENAI_API_KEY,
  });

  /**
   * Analisa uma imagem de produto e retorna atributos estruturados
   *
   * @param imagePath - Caminho local da imagem
   * @returns Objeto com an√°lise estruturada da imagem
   */
  async analyzeImage(imagePath: string): Promise<VisionAnalysisResult> {
    this.logger.debug(`Analisando imagem: ${imagePath}`);

    try {
      // Converte imagem para base64
      const imageBuffer = fs.readFileSync(imagePath);
      const base64Image = imageBuffer.toString('base64');
      const mimeType = this.getMimeType(imagePath);

      // Prompt estruturado para an√°lise de produto
      const analysisPrompt = `Voc√™ √© um especialista em an√°lise de produtos para e-commerce.
Analise esta imagem de produto e retorne APENAS um JSON v√°lido (sem markdown, sem explica√ß√µes) com a seguinte estrutura:

{
  "category": "categoria do produto (ex: roupa, eletr√¥nico, acess√≥rio)",
  "colors": ["cor1", "cor2"],
  "style": "estilo visual (ex: moderno, cl√°ssico, minimalista, esportivo)",
  "materials": ["material1", "material2"],
  "features": ["caracter√≠stica visual 1", "caracter√≠stica visual 2"],
  "detailedDescription": "descri√ß√£o objetiva do que voc√™ v√™ na imagem em 2-3 frases"
}

Seja preciso e objetivo. Use portugu√™s brasileiro.`;

      // Chamada ao modelo com vis√£o
      const response = await this.visionModel.invoke([
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: analysisPrompt,
            },
            {
              type: 'image_url',
              image_url: {
                url: `data:${mimeType};base64,${base64Image}`,
              },
            },
          ],
        },
      ]);

      // üî• Parse da resposta com tipagem correta
      const responseText = this.extractTextFromResponse(response);

      // Remove markdown se houver
      const cleanedText = responseText
        .replace(/```json\n?/g, '')
        .replace(/```\n?/g, '')
        .trim();

      const analysis = JSON.parse(cleanedText) as VisionAnalysisResult;

      this.logger.debug(
        `An√°lise completa: categoria=${analysis.category}, cores=${analysis.colors.length}`,
      );

      return analysis;
    } catch (error) {
      // üî• Tratamento de erro com tipagem correta
      const errorMessage =
        error instanceof Error ? error.message : 'Erro desconhecido';
      const errorStack = error instanceof Error ? error.stack : undefined;

      this.logger.error(`Erro ao analisar imagem: ${errorMessage}`, errorStack);

      // Fallback: retorna an√°lise vazia se falhar
      return {
        category: 'produto',
        colors: [],
        style: 'n√£o identificado',
        materials: [],
        features: [],
        detailedDescription: 'An√°lise visual n√£o dispon√≠vel',
      };
    }
  }

  /**
  /**
   * Extrai texto da resposta do LangChain com tipagem segura
   */
  private extractTextFromResponse(response: AIMessage): string {
    const content = response.content;

    // Caso 1: content √© string diretamente
    if (typeof content === 'string') {
      return content;
    }

    // Caso 2: content √© array
    if (Array.isArray(content)) {
      for (const item of content) {
        if (
          typeof item === 'object' &&
          item !== null &&
          'text' in item &&
          typeof item.text === 'string'
        ) {
          return item.text;
        }
      }
    }

    // Caso 3: content √© objeto (use unknown primeiro para convers√£o segura)
    if (typeof content === 'object' && content !== null && 'text' in content) {
      const unknownContent = content as unknown;
      const messageContent = unknownContent as MessageContent;

      if (typeof messageContent.text === 'string') {
        return messageContent.text;
      }
    }

    // Fallback: serializa como JSON
    return JSON.stringify(content);
  }

  /**
   * Determina o MIME type baseado na extens√£o do arquivo
   */
  private getMimeType(filePath: string): string {
    const ext = path.extname(filePath).toLowerCase();
    const mimeTypes: Record<string, string> = {
      '.jpg': 'image/jpeg',
      '.jpeg': 'image/jpeg',
      '.png': 'image/png',
      '.gif': 'image/gif',
      '.webp': 'image/webp',
    };
    return mimeTypes[ext] || 'image/jpeg';
  }

  /**
   * Formata a an√°lise em texto natural para enriquecer prompts
   */
  formatAnalysisForPrompt(analysis: VisionAnalysisResult): string {
    const parts: string[] = [];

    if (analysis.category && analysis.category !== 'produto') {
      parts.push(`Categoria: ${analysis.category}`);
    }

    if (analysis.colors.length > 0) {
      parts.push(`Cores: ${analysis.colors.join(', ')}`);
    }

    if (analysis.style && analysis.style !== 'n√£o identificado') {
      parts.push(`Estilo: ${analysis.style}`);
    }

    if (analysis.materials.length > 0) {
      parts.push(`Materiais: ${analysis.materials.join(', ')}`);
    }

    if (analysis.features.length > 0) {
      parts.push(`Caracter√≠sticas visuais: ${analysis.features.join('; ')}`);
    }

    if (analysis.detailedDescription) {
      parts.push(`\nDescri√ß√£o visual: ${analysis.detailedDescription}`);
    }

    return parts.join('\n');
  }
}
